{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9e2ee8f",
   "metadata": {},
   "source": [
    "# Exploração da base de dados do RAIS\n",
    "\n",
    "Neste notebook, iremos carregar e realizar exploração de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fcc610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a aquisição e pré-processamento de dados...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando bases da RAIS para o ano 2023:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Tentativa 1: Baixando RAIS_VINC_PUB_SUL.7z via FTP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando bases da RAIS para o ano 2023:   0%|          | 0/1 [25:37<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Arquivo RAIS_VINC_PUB_SUL.7z baixado via FTP.\n",
      "  Extraindo RAIS_VINC_PUB_SUL.7z...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando bases da RAIS para o ano 2023:   0%|          | 0/1 [26:47<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Arquivo RAIS_VINC_PUB_SUL.7z extraído.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando bases da RAIS para o ano 2023:   0%|          | 0/1 [27:43<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dados de RAIS_VINC_PUB_SUL carregados e salvos em RAIS_VINC_PUB_SUL.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando bases da RAIS para o ano 2023: 100%|██████████| 1/1 [27:43<00:00, 1663.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combinando todos os dados regionais...\n",
      "Todos os dados regionais combinados.\n",
      "Renomeando colunas...\n",
      "Colunas renomeadas.\n",
      "Convertendo 'rem_med' para numérico...\n",
      "'rem_med' convertido para numérico.\n",
      "Filtrando dados...\n",
      "Dados filtrados de acordo com 'Vínculo Ativo 31/12' e 'Vl Remun Média Nom'.\n",
      "Calculando a média salarial por município e CBO Ocupação 2002...\n",
      "Média salarial por município e CBO Ocupação 2002 calculada.\n",
      "Média salarial por município e CBO salva em 'C:/Users/john-/OneDrive - Universidade Federal da Paraíba/Área de Trabalho/Artigo - Estatística/projeto-evasao/data/processed\\media_salarial_municipio_cbo_2023.csv'.\n",
      "\n",
      "Processo concluído.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import py7zr\n",
    "from ftplib import FTP\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# --- Configuração ---\n",
    "\n",
    "# Diretório para baixar/extrair os dados brutos\n",
    "WORKING_DIRECTORY = r\"C:/Users/john-/OneDrive - Universidade Federal da Paraíba/Área de Trabalho\\Artigo - Estatística/projeto-evasao/data/raw/rais\"\n",
    "os.makedirs(WORKING_DIRECTORY, exist_ok=True)\n",
    "os.chdir(WORKING_DIRECTORY)\n",
    "\n",
    "# Diretório para salvar os dados processados (resultados)\n",
    "PROCESSED_DIRECTORY = r\"C:/Users/john-/OneDrive - Universidade Federal da Paraíba/Área de Trabalho/Artigo - Estatística/projeto-evasao/data/processed\"\n",
    "os.makedirs(PROCESSED_DIRECTORY, exist_ok=True)\n",
    "\n",
    "YEAR = 2023\n",
    "RAIS_BASES = [\n",
    "    \"RAIS_VINC_PUB_SP\",\n",
    "    \"RAIS_VINC_PUB_CENTRO_OESTE\",\n",
    "    \"RAIS_VINC_PUB_MG_ES_RJ\",\n",
    "    \"RAIS_VINC_PUB_NORDESTE\",\n",
    "    \"RAIS_VINC_PUB_NORTE\",\n",
    "    \"RAIS_VINC_PUB_SUL\",\n",
    "]\n",
    "\n",
    "SELECTED_VARIABLES = [\n",
    "    \"CBO Ocupação 2002\",\n",
    "    \"Vínculo Ativo 31/12\",\n",
    "    \"Vl Remun Média Nom\",\n",
    "    \"Município\",\n",
    "]\n",
    "\n",
    "COLUMN_RENAME_MAP = {\n",
    "    \"CBO Ocupação 2002\": \"cbo_ocup\",\n",
    "    \"Vínculo Ativo 31/12\": \"vic_ativ\",\n",
    "    \"Vl Remun Média Nom\": \"rem_med\",\n",
    "    \"Município\": \"mun\",\n",
    "}\n",
    "\n",
    "# --- Funções Auxiliares ---\n",
    "\n",
    "def download_file(url, dest_path, retries=10, delay=60):\n",
    "    \"\"\"Baixa um arquivo de uma URL (suporta HTTP/HTTPS e FTP) com tentativas.\"\"\"\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            if url.startswith(\"ftp://\"):\n",
    "                from urllib.parse import urlparse\n",
    "                parsed_url = urlparse(url)\n",
    "                ftp_host = parsed_url.hostname\n",
    "                ftp_path = parsed_url.path.lstrip('/')\n",
    "\n",
    "                tqdm.write(f\"  Tentativa {i+1}: Baixando {os.path.basename(dest_path)} via FTP...\")\n",
    "                with FTP(ftp_host) as ftp:\n",
    "                    ftp.login()\n",
    "                    with open(dest_path, 'wb') as fp:\n",
    "                        ftp.retrbinary(f'RETR {ftp_path}', fp.write)\n",
    "                tqdm.write(f\"  Arquivo {os.path.basename(dest_path)} baixado via FTP.\")\n",
    "                return True\n",
    "            else:\n",
    "                tqdm.write(f\"  Tentativa {i+1}: Baixando {os.path.basename(dest_path)} via HTTP/HTTPS...\")\n",
    "                response = requests.get(url, stream=True, timeout=500)\n",
    "                response.raise_for_status()\n",
    "                with open(dest_path, \"wb\") as f:\n",
    "                    for chunk in response.iter_content(chunk_size=8192):\n",
    "                        f.write(chunk)\n",
    "                tqdm.write(f\"  Arquivo {os.path.basename(dest_path)} baixado via HTTP/HTTPS.\")\n",
    "                return True\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"  Tentativa {i+1} falhou ao baixar {os.path.basename(dest_path)}: {e}\")\n",
    "            if i < retries - 1:\n",
    "                tqdm.write(f\"  Tentando novamente em {delay} segundos...\")\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                tqdm.write(f\"  Falha ao baixar {os.path.basename(dest_path)} após {retries} tentativas.\")\n",
    "                return False\n",
    "\n",
    "def extract_7z(file_path, dest_dir):\n",
    "    \"\"\"Extrai um arquivo 7z.\"\"\"\n",
    "    try:\n",
    "        tqdm.write(f\"  Extraindo {os.path.basename(file_path)}...\")\n",
    "        with py7zr.SevenZipFile(file_path, mode=\"r\") as z:\n",
    "            z.extractall(path=dest_dir)\n",
    "        tqdm.write(f\"  Arquivo {os.path.basename(file_path)} extraído.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"  Erro ao extrair {file_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "# --- Aquisição e Pré-processamento de Dados ---\n",
    "\n",
    "def acquire_and_preprocess_data():\n",
    "    all_data_frames = []\n",
    "\n",
    "    for base_name in tqdm(RAIS_BASES, desc=f\"Processando bases da RAIS para o ano {YEAR}\"):\n",
    "        file_7z = f\"{base_name}.7z\"\n",
    "        file_txt = f\"{base_name}.txt\"\n",
    "        ftp_path = f\"ftp://ftp.mtps.gov.br/pdet/microdados/RAIS/{YEAR}/{file_7z}\"\n",
    "        rda_file = f\"{base_name}.pkl\"\n",
    "\n",
    "        if not download_file(ftp_path, file_7z):\n",
    "            continue\n",
    "\n",
    "        if not extract_7z(file_7z, \".\"):\n",
    "            if os.path.exists(file_7z):\n",
    "                os.remove(file_7z)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(\n",
    "                file_txt,\n",
    "                sep=\";\",\n",
    "                usecols=SELECTED_VARIABLES,\n",
    "                encoding=\"latin-1\",\n",
    "                dtype={\"CBO Ocupação 2002\": str},\n",
    "            )\n",
    "            df.to_pickle(rda_file)\n",
    "            all_data_frames.append(df)\n",
    "            tqdm.write(f\"  Dados de {base_name} carregados e salvos em {rda_file}\")\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"  Erro ao carregar ou salvar {file_txt}: {e}\")\n",
    "        finally:\n",
    "            if os.path.exists(file_7z):\n",
    "                os.remove(file_7z)\n",
    "            if os.path.exists(file_txt):\n",
    "                os.remove(file_txt)\n",
    "\n",
    "    if not all_data_frames:\n",
    "        tqdm.write(\"Nenhum data frame foi carregado com sucesso.\")\n",
    "        return None\n",
    "\n",
    "    tqdm.write(\"\\nCombinando todos os dados regionais...\")\n",
    "    x = pd.concat(all_data_frames, ignore_index=True)\n",
    "    tqdm.write(\"Todos os dados regionais combinados.\")\n",
    "\n",
    "    tqdm.write(\"Renomeando colunas...\")\n",
    "    x = x.rename(columns={k: v for k, v in COLUMN_RENAME_MAP.items() if k in x.columns})\n",
    "    tqdm.write(\"Colunas renomeadas.\")\n",
    "\n",
    "    tqdm.write(\"Convertendo 'rem_med' para numérico...\")\n",
    "    x[\"rem_med\"] = x[\"rem_med\"].str.replace(\",\", \".\").astype(float)\n",
    "    tqdm.write(\"'rem_med' convertido para numérico.\")\n",
    "\n",
    "    tqdm.write(\"Filtrando dados...\")\n",
    "    filtered_data = x[\n",
    "        (x[\"vic_ativ\"] == 1)\n",
    "        & (x[\"rem_med\"].between(220, 100000))\n",
    "    ].copy()\n",
    "    tqdm.write(\"Dados filtrados de acordo com 'Vínculo Ativo 31/12' e 'Vl Remun Média Nom'.\")\n",
    "\n",
    "    return filtered_data\n",
    "\n",
    "def calculate_mean_salary_by_municipality_and_cbo(df):\n",
    "    if 'mun' not in df.columns or 'cbo_ocup' not in df.columns or 'rem_med' not in df.columns:\n",
    "        tqdm.write(\"DataFrame não contém as colunas 'mun', 'cbo_ocup' ou 'rem_med'. Não é possível calcular a média salarial.\")\n",
    "        return None\n",
    "\n",
    "    tqdm.write(\"Calculando a média salarial por município e CBO Ocupação 2002...\")\n",
    "    mean_salary = df.groupby(['mun', 'cbo_ocup'])['rem_med'].mean().reset_index()\n",
    "    mean_salary.rename(columns={'rem_med': 'media_salarial'}, inplace=True)\n",
    "    tqdm.write(\"Média salarial por município e CBO Ocupação 2002 calculada.\")\n",
    "    return mean_salary\n",
    "\n",
    "# --- Main Execution ---\n",
    "\n",
    "def main():\n",
    "    tqdm.write(\"Iniciando a aquisição e pré-processamento de dados...\")\n",
    "    filtered_data = acquire_and_preprocess_data()\n",
    "\n",
    "    if filtered_data is None:\n",
    "        tqdm.write(\"Não foi possível adquirir ou pré-processar os dados. O cálculo da média salarial não será realizado.\")\n",
    "        return\n",
    "\n",
    "    if filtered_data.empty:\n",
    "        tqdm.write(\"O DataFrame filtrado está vazio após o pré-processamento. Não há dados para calcular a média salarial.\")\n",
    "        return\n",
    "\n",
    "    mean_salary_df = calculate_mean_salary_by_municipality_and_cbo(filtered_data)\n",
    "\n",
    "    if mean_salary_df is None:\n",
    "        tqdm.write(\"O cálculo da média salarial retornou None (provavelmente devido a colunas ausentes). O arquivo CSV não será salvo.\")\n",
    "    else:\n",
    "        file_path = os.path.join(PROCESSED_DIRECTORY, f\"media_salarial_municipio_cbo_{YEAR}.csv\")\n",
    "        try:\n",
    "            mean_salary_df.to_csv(file_path, index=False)\n",
    "            tqdm.write(f\"Média salarial por município e CBO salva em '{file_path}'.\")\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"Erro ao salvar o arquivo CSV: {e}\")\n",
    "\n",
    "    tqdm.write(\"\\nProcesso concluído.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f2ba788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Checagem de CBOs:\n",
      "- Total de CBOs únicos na base de cursos: 2601\n",
      "- Total de CBOs únicos na base salarial: 2724\n",
      "- Total de CBOs que deram match: 2601\n",
      "- CBOs sem correspondência na base salarial: 0\n",
      "- CBOs sem correspondência na base de cursos: 123\n",
      "\n",
      "📄 CBOs da base de cursos SEM salário:\n",
      "set()\n",
      "\n",
      "📄 CBOs da base salarial SEM curso:\n",
      "{'142125', '253405', '523120', '111120', '20205', '516910', '142130', '10215', '512105', '512110', '423115', '204110', '842220', '322140', '111105', '111115', '21210', '622710', '212425', '253410', '517130', '20110', '30110', '21205', '111245', '10305', '424205', '111250', '111210', '342560', '512115', '31105', '374155', '30205', '20115', '314835', '324135', '142140', '411055', '214540', '999999', '516155', '781310', '223915', '141820', '10105', '715420', '322255', '314840', '375130', '211220', '141815', '223575', '239445', '314830', '141805', '391145', '354610', '375125', '314825', '225355', '141810', '725030', '111205', '524315', '515320', '226110', '422335', '142355', '314805', '10115', '31205', '351435', '212430', '391140', '517230', '223580', '783240', '517120', '234689', '224140', '111110', '314810', '31110', '517125', '324140', '20310', '20305', '516150', '10315', '913125', '316335', '31210', '10205', '21110', '10110', '516905', '842235', '512120', '141830', '10310', '214375', '523125', '222125', '314845', '30105', '213165', '239440', '314815', '21105', '142350', '342555', '422330', '511515', '142135', '20105', '517235', '30115', '214380', '111255', '10210', '30305', '141825'}\n",
      "\n",
      "✅ Merge realizado com sucesso e arquivo salvo!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Definir caminho da pasta\n",
    "caminho = r\"C:\\Users\\john-\\OneDrive - Universidade Federal da Paraíba\\Área de Trabalho\\Artigo - Estatística\\projeto-evasao\\data\\processed\"\n",
    "\n",
    "# Ler os arquivos\n",
    "resultado_match = pd.read_excel(os.path.join(caminho, 'resultado_match_cbo_cursos.xlsx'))\n",
    "media_salarial = pd.read_csv(os.path.join(caminho, 'media_salarial_2018_2023.csv'))\n",
    "\n",
    "# Padronizar a coluna 'cbo_ocup' nas duas bases\n",
    "for df in [resultado_match, media_salarial]:\n",
    "    df['cbo_ocup'] = df['cbo_ocup'].astype(str).str.strip().str.lower()\n",
    "\n",
    "# Remover linhas com cbo_ocup ausente\n",
    "resultado_match = resultado_match.dropna(subset=['cbo_ocup'])\n",
    "media_salarial = media_salarial.dropna(subset=['cbo_ocup'])\n",
    "\n",
    "# Checagem de CBOs únicos nas duas bases\n",
    "cbo_cursos = set(resultado_match['cbo_ocup'].unique())\n",
    "cbo_salarios = set(media_salarial['cbo_ocup'].unique())\n",
    "\n",
    "# Interseção (CBOs que existem nas duas bases)\n",
    "cbo_comum = cbo_cursos.intersection(cbo_salarios)\n",
    "\n",
    "print(\"🔍 Checagem de CBOs:\")\n",
    "print(f\"- Total de CBOs únicos na base de cursos: {len(cbo_cursos)}\")\n",
    "print(f\"- Total de CBOs únicos na base salarial: {len(cbo_salarios)}\")\n",
    "print(f\"- Total de CBOs que deram match: {len(cbo_comum)}\")\n",
    "print(f\"- CBOs sem correspondência na base salarial: {len(cbo_cursos - cbo_salarios)}\")\n",
    "print(f\"- CBOs sem correspondência na base de cursos: {len(cbo_salarios - cbo_cursos)}\")\n",
    "\n",
    "# (Opcional) Listar quais ficaram de fora\n",
    "print(\"\\n📄 CBOs da base de cursos SEM salário:\")\n",
    "print(cbo_cursos - cbo_salarios)\n",
    "\n",
    "print(\"\\n📄 CBOs da base salarial SEM curso:\")\n",
    "print(cbo_salarios - cbo_cursos)\n",
    "\n",
    "# Realizar o merge\n",
    "media_salario_2018_2023 = pd.merge(\n",
    "    resultado_match,\n",
    "    media_salarial,\n",
    "    on='cbo_ocup',\n",
    "    how='inner'  # 'left' se quiser manter todos os cursos\n",
    ")\n",
    "\n",
    "# Salvar o resultado\n",
    "media_salario_2018_2023.to_csv(\n",
    "    os.path.join(caminho, 'media_salario_2018_2023.csv'),\n",
    "    index=False,\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Merge realizado com sucesso e arquivo salvo!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03682cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\john-\\AppData\\Local\\Temp\\ipykernel_23532\\1783581962.py:8: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  media_salario_2018_2023 = pd.read_csv(os.path.join(caminho, 'media_salario_2018_2023.csv'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           mun                          CURSOS  media_salarial_media_2018_2023\n",
      "0       110001                   ADMINISTRAÇÃO                     2823.666662\n",
      "1       110001           ADMINISTRAÇÃO PÚBLICA                     2898.938086\n",
      "2       110001                       AGRONOMIA                     1785.029910\n",
      "3       110001              CIÊNCIAS CONTÁBEIS                     2000.551607\n",
      "4       110001             CIÊNCIAS ECONÔMICAS                     4599.226889\n",
      "...        ...                             ...                             ...\n",
      "225191  999999          ENGENHARIA DE PRODUÇÃO                    16823.255000\n",
      "225192  999999             ENGENHARIA ELÉTRICA                    26242.800000\n",
      "225193  999999             ENGENHARIA MECÂNICA                    48916.565000\n",
      "225194  999999  TECNOLOGIA EM GESTÃO COMERCIAL                    24165.400000\n",
      "225195  999999                         TURISMO                    56922.450000\n",
      "\n",
      "[225196 rows x 3 columns]\n",
      "\n",
      "✅ Média salarial por município e curso calculada e salva com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Definir caminho da pasta\n",
    "caminho = r\"C:\\Users\\john-\\OneDrive - Universidade Federal da Paraíba\\Área de Trabalho\\Artigo - Estatística\\projeto-evasao\\data\\processed\"\n",
    "\n",
    "# Ler o arquivo já com merge\n",
    "media_salario_2018_2023 = pd.read_csv(os.path.join(caminho, 'media_salario_2018_2023.csv'))\n",
    "\n",
    "# Agrupar por 'mun' e 'CURSOS' e calcular a média\n",
    "media_salarial_cursos_2018_2023 = media_salario_2018_2023.groupby(['mun', 'CURSOS']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Visualizar o resultado\n",
    "print(media_salarial_cursos_2018_2023)\n",
    "\n",
    "# Salvar o resultado em CSV\n",
    "media_salarial_cursos_2018_2023.to_csv(\n",
    "    os.path.join(caminho, 'media_salarial_cursos_2018_2023.csv'),\n",
    "    index=False,\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Média salarial por município e curso calculada e salva com sucesso!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90378124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos após tratamento: 1\n",
      "\n",
      "✅ Merge concluído com sucesso e coluna 'salario' adicionada!\n",
      "\n",
      "🔎 Total de registros sem salário encontrado: 54\n",
      "\n",
      "🚩 Combinações sem correspondência de salário:\n",
      "\n",
      "      CÓDIGO_DO_MUNICÍPIO                  ÁREA_DE_AVALIAÇÃO\n",
      "373                431690                     fonoaudiologia\n",
      "588                261160                     fonoaudiologia\n",
      "589                292740                     fonoaudiologia\n",
      "728                330100       tecnologia em design grafico\n",
      "739                314610  tecnologia em gestao da qualidade\n",
      "824                172100       tecnologia em gestao publica\n",
      "865                431490                     fonoaudiologia\n",
      "896                280030                     fonoaudiologia\n",
      "952                130120                           nutricao\n",
      "985                210320                          zootecnia\n",
      "1027               150140       tecnologia em gestao publica\n",
      "1029               432050         tecnologia em agronegocios\n",
      "1176               241120                       fisioterapia\n",
      "1180               240810                     fonoaudiologia\n",
      "1223               431710       tecnologia em gestao publica\n",
      "1230               431440       tecnologia em gestao publica\n",
      "1243               431780         tecnologia em agronegocios\n",
      "1286               420540                     fonoaudiologia\n",
      "1302               250750                     fonoaudiologia\n",
      "1358               330340                     fonoaudiologia\n",
      "1408               431980       tecnologia em gestao publica\n",
      "1415               210232       tecnologia em gestao publica\n",
      "1435               290490       tecnologia em gestao publica\n",
      "1454               280670                             design\n",
      "1465               280350                     fonoaudiologia\n",
      "1475               312600            engenharia de alimentos\n",
      "1502               292790                          zootecnia\n",
      "1542               410690       tecnologia em gestao publica\n",
      "1547                 <NA>            relacoes internacionais\n",
      "1586               240810       tecnologia em gestao publica\n",
      "1591               251630       tecnologia em gestao publica\n",
      "1668               313060            engenharia de alimentos\n",
      "1684               431120         tecnologia em agronegocios\n",
      "1704               530010       tecnologia em gestao publica\n",
      "1718               521020         tecnologia em agronegocios\n",
      "1738               510675    tecnologia em comercio exterior\n",
      "1768               530010                     fonoaudiologia\n",
      "1780               110020       tecnologia em gestao publica\n",
      "1980               316280               engenharia florestal\n",
      "1993               520890            arquitetura e urbanismo\n",
      "2001               240940            arquitetura e urbanismo\n",
      "2043               250400         engenharia de computacao i\n",
      "2047               510840       tecnologia em gestao publica\n",
      "2089               510180       tecnologia em gestao publica\n",
      "2102               220780                          zootecnia\n",
      "2117               421580         engenharia de computacao i\n",
      "2129               170950       tecnologia em gestao publica\n",
      "2137               355030       tecnologia em gestao publica\n",
      "2172               500500            arquitetura e urbanismo\n",
      "2204               410140         engenharia de computacao i\n",
      "2206               260680  tecnologia em gestao da qualidade\n",
      "2234               412140                           nutricao\n",
      "\n",
      "✅ Arquivo 'combinacoes_sem_salario.csv' salvo com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import unicodedata\n",
    "\n",
    "# =========================\n",
    "# Função para padronizar texto\n",
    "# =========================\n",
    "def padronizar_texto(texto):\n",
    "    if pd.isna(texto):\n",
    "        return ''\n",
    "    texto = str(texto).strip().lower()\n",
    "    texto = unicodedata.normalize('NFKD', texto).encode('ASCII', 'ignore').decode('utf-8')\n",
    "    texto = texto.replace('-', ' ').replace('_', ' ')\n",
    "    texto = ' '.join(texto.split())\n",
    "    return texto\n",
    "\n",
    "# =========================\n",
    "# Caminho\n",
    "# =========================\n",
    "caminho = r\"C:\\Users\\john-\\OneDrive - Universidade Federal da Paraíba\\Área de Trabalho\\Artigo - Estatística\\projeto-evasao\\data\\processed\"\n",
    "\n",
    "# =========================\n",
    "# Leitura dos arquivos\n",
    "# =========================\n",
    "ml_iq_2018_2023 = pd.read_csv(os.path.join(caminho, 'ml_iq_2018_2023.csv'))\n",
    "media_salarial_cursos_2018_2023 = pd.read_csv(os.path.join(caminho, 'media_salarial_cursos_2018_2023.csv'))\n",
    "\n",
    "# =========================\n",
    "# Tratamento da coluna CÓDIGO_DO_MUNICÍPIO\n",
    "# =========================\n",
    "cod_mun = (\n",
    "    ml_iq_2018_2023['CÓDIGO_DO_MUNICÍPIO']\n",
    "    .astype(str)\n",
    "    .str.replace('.', '', regex=False)\n",
    "    .str[:-1]\n",
    ")\n",
    "\n",
    "# Converte para número, forçando valores inválidos a NaN e usando Int64 para permitir nulos\n",
    "ml_iq_2018_2023['CÓDIGO_DO_MUNICÍPIO'] = pd.to_numeric(cod_mun, errors='coerce').astype('Int64')\n",
    "\n",
    "print(f\"Valores nulos após tratamento: {ml_iq_2018_2023['CÓDIGO_DO_MUNICÍPIO'].isna().sum()}\")\n",
    "\n",
    "# =========================\n",
    "# Padronização dos nomes dos cursos\n",
    "# =========================\n",
    "ml_iq_2018_2023['ÁREA_DE_AVALIAÇÃO'] = ml_iq_2018_2023['ÁREA_DE_AVALIAÇÃO'].apply(padronizar_texto)\n",
    "media_salarial_cursos_2018_2023['CURSOS'] = media_salarial_cursos_2018_2023['CURSOS'].apply(padronizar_texto)\n",
    "\n",
    "# =========================\n",
    "# Merge dos dataframes\n",
    "# =========================\n",
    "df_merged = ml_iq_2018_2023.merge(\n",
    "    media_salarial_cursos_2018_2023,\n",
    "    left_on=['CÓDIGO_DO_MUNICÍPIO', 'ÁREA_DE_AVALIAÇÃO'],\n",
    "    right_on=['mun', 'CURSOS'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Criar coluna 'salario'\n",
    "# =========================\n",
    "df_merged['salario'] = df_merged['media_salarial_media_2018_2023']\n",
    "\n",
    "# =========================\n",
    "# Salvar o novo dataframe\n",
    "# =========================\n",
    "df_merged.to_csv(\n",
    "    os.path.join(caminho, 'ml_iq_2018_2023.csv'),\n",
    "    index=False,\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Merge concluído com sucesso e coluna 'salario' adicionada!\")\n",
    "\n",
    "# =========================\n",
    "# Verificar combinações sem salário\n",
    "# =========================\n",
    "na_salario = df_merged[df_merged['salario'].isna()]\n",
    "\n",
    "print(f\"\\n🔎 Total de registros sem salário encontrado: {len(na_salario)}\")\n",
    "\n",
    "combinacoes_sem_match = na_salario[['CÓDIGO_DO_MUNICÍPIO', 'ÁREA_DE_AVALIAÇÃO']].drop_duplicates()\n",
    "\n",
    "print(\"\\n🚩 Combinações sem correspondência de salário:\\n\")\n",
    "print(combinacoes_sem_match)\n",
    "\n",
    "combinacoes_sem_match.to_csv(\n",
    "    os.path.join(caminho, 'combinacoes_sem_salario.csv'),\n",
    "    index=False,\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Arquivo 'combinacoes_sem_salario.csv' salvo com sucesso!\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9094cd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas atuais: ['CÓDIGO_DA_IES', 'NOME_DA_IES', 'SIGLA_DA_IES', 'ORGANIZAÇÃO_ACADÊMICA', 'CATEGORIA_ADMINISTRATIVA', 'CÓDIGO_DO_CURSO', 'CÓDIGO_DA_ÁREA', 'ÁREA_DE_AVALIAÇÃO', 'MODALIDADE_DE_ENSINO', 'CÓDIGO_DO_MUNICÍPIO', 'MUNICÍPIO_DO_CURSO', 'SIGLA_DA_UF', 'NOTA_PADRONIZADA_-_IDD', 'NOTA_PADRONIZADA_-_ORGANIZAÇÃO_DIDÁTICO-PEDAGÓGICA', 'NOTA_PADRONIZADA_-_INFRAESTRUTURA_E_INSTALAÇÕES_FÍSICAS', 'NOTA_PADRONIZADA_-_OPORTUNIDADE_DE_AMPLIAÇÃO_DA_FORMAÇÃO', 'NOTA_PADRONIZADA_-_MESTRES', 'NOTA_PADRONIZADA_-_DOUTORES', 'MEDIA_CONCEITO_ENADE_(CONTÍNUO)', 'IDD_(CONTÍNUO)', 'CONCEITO_MÉDIO_DE_GRADUAÇÃO', 'IGC_(CONTÍNUO)', 'TDA', 'TDA_binaria', 'mun', 'CURSOS', 'media_salarial_media_2018_2023', 'salario']\n",
      "Arquivo salvo sem as colunas indicadas.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Caminho do arquivo\n",
    "caminho = r\"C:\\Users\\john-\\OneDrive - Universidade Federal da Paraíba\\Área de Trabalho\\Artigo - Estatística\\projeto-evasao\\data\\processed\"\n",
    "arquivo = \"ml_iq_2018_2023.csv\"\n",
    "\n",
    "# Carregar o dataframe\n",
    "df_merged = pd.read_csv(os.path.join(caminho, arquivo))\n",
    "\n",
    "# Mostrar as colunas atuais para garantir que as que deseja excluir existem\n",
    "print(\"Colunas atuais:\", df_merged.columns.tolist())\n",
    "\n",
    "# Excluir as colunas, ignorando erro se não existir\n",
    "colunas_para_excluir = ['mun', 'CURSOS', 'media_salarial_media_2018_2023', 'salario']\n",
    "df_merged = df_merged.drop(columns=[col for col in colunas_para_excluir if col in df_merged.columns])\n",
    "\n",
    "# Salvar o novo dataframe sem essas colunas\n",
    "df_merged.to_csv(\n",
    "    os.path.join(caminho, 'ml_iq_2018_2023_sem_colunas.csv'),\n",
    "    index=False,\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "\n",
    "print(\"Arquivo salvo sem as colunas indicadas.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4deb9d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo salvo em: C:\\Users\\john-\\OneDrive - Universidade Federal da Paraíba\\Área de Trabalho\\Artigo - Estatística\\projeto-evasao\\data\\processed\\ml_iq_2018_2023_alterado.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Caminho do arquivo original\n",
    "caminho_arquivo = r\"C:\\Users\\john-\\OneDrive - Universidade Federal da Paraíba\\Área de Trabalho\\Artigo - Estatística\\projeto-evasao\\data\\processed\\ml_iq_2018_2023.csv\"\n",
    "\n",
    "# Carregar o DataFrame\n",
    "ml_iq_2018_2023 = pd.read_csv(caminho_arquivo)\n",
    "\n",
    "# Garantir que a coluna seja string\n",
    "ml_iq_2018_2023['CÓDIGO_DO_MUNICÍPIO'] = ml_iq_2018_2023['CÓDIGO_DO_MUNICÍPIO'].astype(str)\n",
    "\n",
    "# Pegar os 6 primeiros dígitos\n",
    "ml_iq_2018_2023['CÓDIGO_DO_MUNICÍPIO'] = ml_iq_2018_2023['CÓDIGO_DO_MUNICÍPIO'].str[:6]\n",
    "\n",
    "# Converter para inteiro\n",
    "ml_iq_2018_2023['CÓDIGO_DO_MUNICÍPIO'] = ml_iq_2018_2023['CÓDIGO_DO_MUNICÍPIO'].astype(int)\n",
    "\n",
    "# Salvar em um novo arquivo CSV\n",
    "novo_caminho = r\"C:\\Users\\john-\\OneDrive - Universidade Federal da Paraíba\\Área de Trabalho\\Artigo - Estatística\\projeto-evasao\\data\\processed\\ml_iq_2018_2023_alterado.csv\"\n",
    "ml_iq_2018_2023.to_csv(novo_caminho, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"Arquivo salvo em:\", novo_caminho)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8da7384d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo salvo após remoção de missing values.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Caminho do arquivo\n",
    "caminho = r\"C:\\Users\\john-\\OneDrive - Universidade Federal da Paraíba\\Área de Trabalho\\Artigo - Estatística\\projeto-evasao\\data\\processed\"\n",
    "arquivo = \"ml_iq_2018_2023.csv\"\n",
    "caminho_arquivo = os.path.join(caminho, arquivo)\n",
    "\n",
    "# Carregar o dataframe\n",
    "df = pd.read_csv(caminho_arquivo)\n",
    "\n",
    "# Remover linhas com missing values\n",
    "df_limpo = df.dropna()\n",
    "\n",
    "# Salvar sobrescrevendo o arquivo original\n",
    "df_limpo.to_csv(caminho_arquivo, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"Arquivo salvo após remoção de missing values.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4efcfdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overflow: resultado é praticamente zero.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Tentando diretamente (gera overflow)\n",
    "try:\n",
    "    resultado = 1 / (1 + math.exp(9995))\n",
    "    print(resultado)\n",
    "except OverflowError:\n",
    "    print(\"Overflow: resultado é praticamente zero.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
