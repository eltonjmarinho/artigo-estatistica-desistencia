{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9e2ee8f",
   "metadata": {},
   "source": [
    "# Explora√ß√£o da base de dados do RAIS\n",
    "\n",
    "Neste notebook, iremos carregar e realizar explora√ß√£o de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fcc610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a aquisi√ß√£o e pr√©-processamento de dados...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando bases da RAIS para o ano 2023:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Tentativa 1: Baixando RAIS_VINC_PUB_SUL.7z via FTP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando bases da RAIS para o ano 2023:   0%|          | 0/1 [25:37<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Arquivo RAIS_VINC_PUB_SUL.7z baixado via FTP.\n",
      "  Extraindo RAIS_VINC_PUB_SUL.7z...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando bases da RAIS para o ano 2023:   0%|          | 0/1 [26:47<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Arquivo RAIS_VINC_PUB_SUL.7z extra√≠do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando bases da RAIS para o ano 2023:   0%|          | 0/1 [27:43<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dados de RAIS_VINC_PUB_SUL carregados e salvos em RAIS_VINC_PUB_SUL.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando bases da RAIS para o ano 2023: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [27:43<00:00, 1663.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combinando todos os dados regionais...\n",
      "Todos os dados regionais combinados.\n",
      "Renomeando colunas...\n",
      "Colunas renomeadas.\n",
      "Convertendo 'rem_med' para num√©rico...\n",
      "'rem_med' convertido para num√©rico.\n",
      "Filtrando dados...\n",
      "Dados filtrados de acordo com 'V√≠nculo Ativo 31/12' e 'Vl Remun M√©dia Nom'.\n",
      "Calculando a m√©dia salarial por munic√≠pio e CBO Ocupa√ß√£o 2002...\n",
      "M√©dia salarial por munic√≠pio e CBO Ocupa√ß√£o 2002 calculada.\n",
      "M√©dia salarial por munic√≠pio e CBO salva em 'C:/Users/john-/OneDrive - Universidade Federal da Para√≠ba/√Årea de Trabalho/Artigo - Estat√≠stica/projeto-evasao/data/processed\\media_salarial_municipio_cbo_2023.csv'.\n",
      "\n",
      "Processo conclu√≠do.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import py7zr\n",
    "from ftplib import FTP\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# --- Configura√ß√£o ---\n",
    "\n",
    "# Diret√≥rio para baixar/extrair os dados brutos\n",
    "WORKING_DIRECTORY = r\"C:/Users/john-/OneDrive - Universidade Federal da Para√≠ba/√Årea de Trabalho\\Artigo - Estat√≠stica/projeto-evasao/data/raw/rais\"\n",
    "os.makedirs(WORKING_DIRECTORY, exist_ok=True)\n",
    "os.chdir(WORKING_DIRECTORY)\n",
    "\n",
    "# Diret√≥rio para salvar os dados processados (resultados)\n",
    "PROCESSED_DIRECTORY = r\"C:/Users/john-/OneDrive - Universidade Federal da Para√≠ba/√Årea de Trabalho/Artigo - Estat√≠stica/projeto-evasao/data/processed\"\n",
    "os.makedirs(PROCESSED_DIRECTORY, exist_ok=True)\n",
    "\n",
    "YEAR = 2023\n",
    "RAIS_BASES = [\n",
    "    \"RAIS_VINC_PUB_SP\",\n",
    "    \"RAIS_VINC_PUB_CENTRO_OESTE\",\n",
    "    \"RAIS_VINC_PUB_MG_ES_RJ\",\n",
    "    \"RAIS_VINC_PUB_NORDESTE\",\n",
    "    \"RAIS_VINC_PUB_NORTE\",\n",
    "    \"RAIS_VINC_PUB_SUL\",\n",
    "]\n",
    "\n",
    "SELECTED_VARIABLES = [\n",
    "    \"CBO Ocupa√ß√£o 2002\",\n",
    "    \"V√≠nculo Ativo 31/12\",\n",
    "    \"Vl Remun M√©dia Nom\",\n",
    "    \"Munic√≠pio\",\n",
    "]\n",
    "\n",
    "COLUMN_RENAME_MAP = {\n",
    "    \"CBO Ocupa√ß√£o 2002\": \"cbo_ocup\",\n",
    "    \"V√≠nculo Ativo 31/12\": \"vic_ativ\",\n",
    "    \"Vl Remun M√©dia Nom\": \"rem_med\",\n",
    "    \"Munic√≠pio\": \"mun\",\n",
    "}\n",
    "\n",
    "# --- Fun√ß√µes Auxiliares ---\n",
    "\n",
    "def download_file(url, dest_path, retries=10, delay=60):\n",
    "    \"\"\"Baixa um arquivo de uma URL (suporta HTTP/HTTPS e FTP) com tentativas.\"\"\"\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            if url.startswith(\"ftp://\"):\n",
    "                from urllib.parse import urlparse\n",
    "                parsed_url = urlparse(url)\n",
    "                ftp_host = parsed_url.hostname\n",
    "                ftp_path = parsed_url.path.lstrip('/')\n",
    "\n",
    "                tqdm.write(f\"  Tentativa {i+1}: Baixando {os.path.basename(dest_path)} via FTP...\")\n",
    "                with FTP(ftp_host) as ftp:\n",
    "                    ftp.login()\n",
    "                    with open(dest_path, 'wb') as fp:\n",
    "                        ftp.retrbinary(f'RETR {ftp_path}', fp.write)\n",
    "                tqdm.write(f\"  Arquivo {os.path.basename(dest_path)} baixado via FTP.\")\n",
    "                return True\n",
    "            else:\n",
    "                tqdm.write(f\"  Tentativa {i+1}: Baixando {os.path.basename(dest_path)} via HTTP/HTTPS...\")\n",
    "                response = requests.get(url, stream=True, timeout=500)\n",
    "                response.raise_for_status()\n",
    "                with open(dest_path, \"wb\") as f:\n",
    "                    for chunk in response.iter_content(chunk_size=8192):\n",
    "                        f.write(chunk)\n",
    "                tqdm.write(f\"  Arquivo {os.path.basename(dest_path)} baixado via HTTP/HTTPS.\")\n",
    "                return True\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"  Tentativa {i+1} falhou ao baixar {os.path.basename(dest_path)}: {e}\")\n",
    "            if i < retries - 1:\n",
    "                tqdm.write(f\"  Tentando novamente em {delay} segundos...\")\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                tqdm.write(f\"  Falha ao baixar {os.path.basename(dest_path)} ap√≥s {retries} tentativas.\")\n",
    "                return False\n",
    "\n",
    "def extract_7z(file_path, dest_dir):\n",
    "    \"\"\"Extrai um arquivo 7z.\"\"\"\n",
    "    try:\n",
    "        tqdm.write(f\"  Extraindo {os.path.basename(file_path)}...\")\n",
    "        with py7zr.SevenZipFile(file_path, mode=\"r\") as z:\n",
    "            z.extractall(path=dest_dir)\n",
    "        tqdm.write(f\"  Arquivo {os.path.basename(file_path)} extra√≠do.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"  Erro ao extrair {file_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "# --- Aquisi√ß√£o e Pr√©-processamento de Dados ---\n",
    "\n",
    "def acquire_and_preprocess_data():\n",
    "    all_data_frames = []\n",
    "\n",
    "    for base_name in tqdm(RAIS_BASES, desc=f\"Processando bases da RAIS para o ano {YEAR}\"):\n",
    "        file_7z = f\"{base_name}.7z\"\n",
    "        file_txt = f\"{base_name}.txt\"\n",
    "        ftp_path = f\"ftp://ftp.mtps.gov.br/pdet/microdados/RAIS/{YEAR}/{file_7z}\"\n",
    "        rda_file = f\"{base_name}.pkl\"\n",
    "\n",
    "        if not download_file(ftp_path, file_7z):\n",
    "            continue\n",
    "\n",
    "        if not extract_7z(file_7z, \".\"):\n",
    "            if os.path.exists(file_7z):\n",
    "                os.remove(file_7z)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(\n",
    "                file_txt,\n",
    "                sep=\";\",\n",
    "                usecols=SELECTED_VARIABLES,\n",
    "                encoding=\"latin-1\",\n",
    "                dtype={\"CBO Ocupa√ß√£o 2002\": str},\n",
    "            )\n",
    "            df.to_pickle(rda_file)\n",
    "            all_data_frames.append(df)\n",
    "            tqdm.write(f\"  Dados de {base_name} carregados e salvos em {rda_file}\")\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"  Erro ao carregar ou salvar {file_txt}: {e}\")\n",
    "        finally:\n",
    "            if os.path.exists(file_7z):\n",
    "                os.remove(file_7z)\n",
    "            if os.path.exists(file_txt):\n",
    "                os.remove(file_txt)\n",
    "\n",
    "    if not all_data_frames:\n",
    "        tqdm.write(\"Nenhum data frame foi carregado com sucesso.\")\n",
    "        return None\n",
    "\n",
    "    tqdm.write(\"\\nCombinando todos os dados regionais...\")\n",
    "    x = pd.concat(all_data_frames, ignore_index=True)\n",
    "    tqdm.write(\"Todos os dados regionais combinados.\")\n",
    "\n",
    "    tqdm.write(\"Renomeando colunas...\")\n",
    "    x = x.rename(columns={k: v for k, v in COLUMN_RENAME_MAP.items() if k in x.columns})\n",
    "    tqdm.write(\"Colunas renomeadas.\")\n",
    "\n",
    "    tqdm.write(\"Convertendo 'rem_med' para num√©rico...\")\n",
    "    x[\"rem_med\"] = x[\"rem_med\"].str.replace(\",\", \".\").astype(float)\n",
    "    tqdm.write(\"'rem_med' convertido para num√©rico.\")\n",
    "\n",
    "    tqdm.write(\"Filtrando dados...\")\n",
    "    filtered_data = x[\n",
    "        (x[\"vic_ativ\"] == 1)\n",
    "        & (x[\"rem_med\"].between(220, 100000))\n",
    "    ].copy()\n",
    "    tqdm.write(\"Dados filtrados de acordo com 'V√≠nculo Ativo 31/12' e 'Vl Remun M√©dia Nom'.\")\n",
    "\n",
    "    return filtered_data\n",
    "\n",
    "def calculate_mean_salary_by_municipality_and_cbo(df):\n",
    "    if 'mun' not in df.columns or 'cbo_ocup' not in df.columns or 'rem_med' not in df.columns:\n",
    "        tqdm.write(\"DataFrame n√£o cont√©m as colunas 'mun', 'cbo_ocup' ou 'rem_med'. N√£o √© poss√≠vel calcular a m√©dia salarial.\")\n",
    "        return None\n",
    "\n",
    "    tqdm.write(\"Calculando a m√©dia salarial por munic√≠pio e CBO Ocupa√ß√£o 2002...\")\n",
    "    mean_salary = df.groupby(['mun', 'cbo_ocup'])['rem_med'].mean().reset_index()\n",
    "    mean_salary.rename(columns={'rem_med': 'media_salarial'}, inplace=True)\n",
    "    tqdm.write(\"M√©dia salarial por munic√≠pio e CBO Ocupa√ß√£o 2002 calculada.\")\n",
    "    return mean_salary\n",
    "\n",
    "# --- Main Execution ---\n",
    "\n",
    "def main():\n",
    "    tqdm.write(\"Iniciando a aquisi√ß√£o e pr√©-processamento de dados...\")\n",
    "    filtered_data = acquire_and_preprocess_data()\n",
    "\n",
    "    if filtered_data is None:\n",
    "        tqdm.write(\"N√£o foi poss√≠vel adquirir ou pr√©-processar os dados. O c√°lculo da m√©dia salarial n√£o ser√° realizado.\")\n",
    "        return\n",
    "\n",
    "    if filtered_data.empty:\n",
    "        tqdm.write(\"O DataFrame filtrado est√° vazio ap√≥s o pr√©-processamento. N√£o h√° dados para calcular a m√©dia salarial.\")\n",
    "        return\n",
    "\n",
    "    mean_salary_df = calculate_mean_salary_by_municipality_and_cbo(filtered_data)\n",
    "\n",
    "    if mean_salary_df is None:\n",
    "        tqdm.write(\"O c√°lculo da m√©dia salarial retornou None (provavelmente devido a colunas ausentes). O arquivo CSV n√£o ser√° salvo.\")\n",
    "    else:\n",
    "        file_path = os.path.join(PROCESSED_DIRECTORY, f\"media_salarial_municipio_cbo_{YEAR}.csv\")\n",
    "        try:\n",
    "            mean_salary_df.to_csv(file_path, index=False)\n",
    "            tqdm.write(f\"M√©dia salarial por munic√≠pio e CBO salva em '{file_path}'.\")\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"Erro ao salvar o arquivo CSV: {e}\")\n",
    "\n",
    "    tqdm.write(\"\\nProcesso conclu√≠do.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f2ba788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checagem de CBOs:\n",
      "- Total de CBOs √∫nicos na base de cursos: 2601\n",
      "- Total de CBOs √∫nicos na base salarial: 2724\n",
      "- Total de CBOs que deram match: 2601\n",
      "- CBOs sem correspond√™ncia na base salarial: 0\n",
      "- CBOs sem correspond√™ncia na base de cursos: 123\n",
      "\n",
      "üìÑ CBOs da base de cursos SEM sal√°rio:\n",
      "set()\n",
      "\n",
      "üìÑ CBOs da base salarial SEM curso:\n",
      "{'142125', '253405', '523120', '111120', '20205', '516910', '142130', '10215', '512105', '512110', '423115', '204110', '842220', '322140', '111105', '111115', '21210', '622710', '212425', '253410', '517130', '20110', '30110', '21205', '111245', '10305', '424205', '111250', '111210', '342560', '512115', '31105', '374155', '30205', '20115', '314835', '324135', '142140', '411055', '214540', '999999', '516155', '781310', '223915', '141820', '10105', '715420', '322255', '314840', '375130', '211220', '141815', '223575', '239445', '314830', '141805', '391145', '354610', '375125', '314825', '225355', '141810', '725030', '111205', '524315', '515320', '226110', '422335', '142355', '314805', '10115', '31205', '351435', '212430', '391140', '517230', '223580', '783240', '517120', '234689', '224140', '111110', '314810', '31110', '517125', '324140', '20310', '20305', '516150', '10315', '913125', '316335', '31210', '10205', '21110', '10110', '516905', '842235', '512120', '141830', '10310', '214375', '523125', '222125', '314845', '30105', '213165', '239440', '314815', '21105', '142350', '342555', '422330', '511515', '142135', '20105', '517235', '30115', '214380', '111255', '10210', '30305', '141825'}\n",
      "\n",
      "‚úÖ Merge realizado com sucesso e arquivo salvo!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Definir caminho da pasta\n",
    "caminho = r\"C:\\Users\\john-\\OneDrive - Universidade Federal da Para√≠ba\\√Årea de Trabalho\\Artigo - Estat√≠stica\\projeto-evasao\\data\\processed\"\n",
    "\n",
    "# Ler os arquivos\n",
    "resultado_match = pd.read_excel(os.path.join(caminho, 'resultado_match_cbo_cursos.xlsx'))\n",
    "media_salarial = pd.read_csv(os.path.join(caminho, 'media_salarial_2018_2023.csv'))\n",
    "\n",
    "# Padronizar a coluna 'cbo_ocup' nas duas bases\n",
    "for df in [resultado_match, media_salarial]:\n",
    "    df['cbo_ocup'] = df['cbo_ocup'].astype(str).str.strip().str.lower()\n",
    "\n",
    "# Remover linhas com cbo_ocup ausente\n",
    "resultado_match = resultado_match.dropna(subset=['cbo_ocup'])\n",
    "media_salarial = media_salarial.dropna(subset=['cbo_ocup'])\n",
    "\n",
    "# Checagem de CBOs √∫nicos nas duas bases\n",
    "cbo_cursos = set(resultado_match['cbo_ocup'].unique())\n",
    "cbo_salarios = set(media_salarial['cbo_ocup'].unique())\n",
    "\n",
    "# Interse√ß√£o (CBOs que existem nas duas bases)\n",
    "cbo_comum = cbo_cursos.intersection(cbo_salarios)\n",
    "\n",
    "print(\"üîç Checagem de CBOs:\")\n",
    "print(f\"- Total de CBOs √∫nicos na base de cursos: {len(cbo_cursos)}\")\n",
    "print(f\"- Total de CBOs √∫nicos na base salarial: {len(cbo_salarios)}\")\n",
    "print(f\"- Total de CBOs que deram match: {len(cbo_comum)}\")\n",
    "print(f\"- CBOs sem correspond√™ncia na base salarial: {len(cbo_cursos - cbo_salarios)}\")\n",
    "print(f\"- CBOs sem correspond√™ncia na base de cursos: {len(cbo_salarios - cbo_cursos)}\")\n",
    "\n",
    "# (Opcional) Listar quais ficaram de fora\n",
    "print(\"\\nüìÑ CBOs da base de cursos SEM sal√°rio:\")\n",
    "print(cbo_cursos - cbo_salarios)\n",
    "\n",
    "print(\"\\nüìÑ CBOs da base salarial SEM curso:\")\n",
    "print(cbo_salarios - cbo_cursos)\n",
    "\n",
    "# Realizar o merge\n",
    "media_salario_2018_2023 = pd.merge(\n",
    "    resultado_match,\n",
    "    media_salarial,\n",
    "    on='cbo_ocup',\n",
    "    how='inner'  # 'left' se quiser manter todos os cursos\n",
    ")\n",
    "\n",
    "# Salvar o resultado\n",
    "media_salario_2018_2023.to_csv(\n",
    "    os.path.join(caminho, 'media_salario_2018_2023.csv'),\n",
    "    index=False,\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Merge realizado com sucesso e arquivo salvo!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03682cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\john-\\AppData\\Local\\Temp\\ipykernel_23532\\1783581962.py:8: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  media_salario_2018_2023 = pd.read_csv(os.path.join(caminho, 'media_salario_2018_2023.csv'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           mun                          CURSOS  media_salarial_media_2018_2023\n",
      "0       110001                   ADMINISTRA√á√ÉO                     2823.666662\n",
      "1       110001           ADMINISTRA√á√ÉO P√öBLICA                     2898.938086\n",
      "2       110001                       AGRONOMIA                     1785.029910\n",
      "3       110001              CI√äNCIAS CONT√ÅBEIS                     2000.551607\n",
      "4       110001             CI√äNCIAS ECON√îMICAS                     4599.226889\n",
      "...        ...                             ...                             ...\n",
      "225191  999999          ENGENHARIA DE PRODU√á√ÉO                    16823.255000\n",
      "225192  999999             ENGENHARIA EL√âTRICA                    26242.800000\n",
      "225193  999999             ENGENHARIA MEC√ÇNICA                    48916.565000\n",
      "225194  999999  TECNOLOGIA EM GEST√ÉO COMERCIAL                    24165.400000\n",
      "225195  999999                         TURISMO                    56922.450000\n",
      "\n",
      "[225196 rows x 3 columns]\n",
      "\n",
      "‚úÖ M√©dia salarial por munic√≠pio e curso calculada e salva com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Definir caminho da pasta\n",
    "caminho = r\"C:\\Users\\john-\\OneDrive - Universidade Federal da Para√≠ba\\√Årea de Trabalho\\Artigo - Estat√≠stica\\projeto-evasao\\data\\processed\"\n",
    "\n",
    "# Ler o arquivo j√° com merge\n",
    "media_salario_2018_2023 = pd.read_csv(os.path.join(caminho, 'media_salario_2018_2023.csv'))\n",
    "\n",
    "# Agrupar por 'mun' e 'CURSOS' e calcular a m√©dia\n",
    "media_salarial_cursos_2018_2023 = media_salario_2018_2023.groupby(['mun', 'CURSOS']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Visualizar o resultado\n",
    "print(media_salarial_cursos_2018_2023)\n",
    "\n",
    "# Salvar o resultado em CSV\n",
    "media_salarial_cursos_2018_2023.to_csv(\n",
    "    os.path.join(caminho, 'media_salarial_cursos_2018_2023.csv'),\n",
    "    index=False,\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ M√©dia salarial por munic√≠pio e curso calculada e salva com sucesso!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90378124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos ap√≥s tratamento: 1\n",
      "\n",
      "‚úÖ Merge conclu√≠do com sucesso e coluna 'salario' adicionada!\n",
      "\n",
      "üîé Total de registros sem sal√°rio encontrado: 54\n",
      "\n",
      "üö© Combina√ß√µes sem correspond√™ncia de sal√°rio:\n",
      "\n",
      "      C√ìDIGO_DO_MUNIC√çPIO                  √ÅREA_DE_AVALIA√á√ÉO\n",
      "373                431690                     fonoaudiologia\n",
      "588                261160                     fonoaudiologia\n",
      "589                292740                     fonoaudiologia\n",
      "728                330100       tecnologia em design grafico\n",
      "739                314610  tecnologia em gestao da qualidade\n",
      "824                172100       tecnologia em gestao publica\n",
      "865                431490                     fonoaudiologia\n",
      "896                280030                     fonoaudiologia\n",
      "952                130120                           nutricao\n",
      "985                210320                          zootecnia\n",
      "1027               150140       tecnologia em gestao publica\n",
      "1029               432050         tecnologia em agronegocios\n",
      "1176               241120                       fisioterapia\n",
      "1180               240810                     fonoaudiologia\n",
      "1223               431710       tecnologia em gestao publica\n",
      "1230               431440       tecnologia em gestao publica\n",
      "1243               431780         tecnologia em agronegocios\n",
      "1286               420540                     fonoaudiologia\n",
      "1302               250750                     fonoaudiologia\n",
      "1358               330340                     fonoaudiologia\n",
      "1408               431980       tecnologia em gestao publica\n",
      "1415               210232       tecnologia em gestao publica\n",
      "1435               290490       tecnologia em gestao publica\n",
      "1454               280670                             design\n",
      "1465               280350                     fonoaudiologia\n",
      "1475               312600            engenharia de alimentos\n",
      "1502               292790                          zootecnia\n",
      "1542               410690       tecnologia em gestao publica\n",
      "1547                 <NA>            relacoes internacionais\n",
      "1586               240810       tecnologia em gestao publica\n",
      "1591               251630       tecnologia em gestao publica\n",
      "1668               313060            engenharia de alimentos\n",
      "1684               431120         tecnologia em agronegocios\n",
      "1704               530010       tecnologia em gestao publica\n",
      "1718               521020         tecnologia em agronegocios\n",
      "1738               510675    tecnologia em comercio exterior\n",
      "1768               530010                     fonoaudiologia\n",
      "1780               110020       tecnologia em gestao publica\n",
      "1980               316280               engenharia florestal\n",
      "1993               520890            arquitetura e urbanismo\n",
      "2001               240940            arquitetura e urbanismo\n",
      "2043               250400         engenharia de computacao i\n",
      "2047               510840       tecnologia em gestao publica\n",
      "2089               510180       tecnologia em gestao publica\n",
      "2102               220780                          zootecnia\n",
      "2117               421580         engenharia de computacao i\n",
      "2129               170950       tecnologia em gestao publica\n",
      "2137               355030       tecnologia em gestao publica\n",
      "2172               500500            arquitetura e urbanismo\n",
      "2204               410140         engenharia de computacao i\n",
      "2206               260680  tecnologia em gestao da qualidade\n",
      "2234               412140                           nutricao\n",
      "\n",
      "‚úÖ Arquivo 'combinacoes_sem_salario.csv' salvo com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import unicodedata\n",
    "\n",
    "# =========================\n",
    "# Fun√ß√£o para padronizar texto\n",
    "# =========================\n",
    "def padronizar_texto(texto):\n",
    "    if pd.isna(texto):\n",
    "        return ''\n",
    "    texto = str(texto).strip().lower()\n",
    "    texto = unicodedata.normalize('NFKD', texto).encode('ASCII', 'ignore').decode('utf-8')\n",
    "    texto = texto.replace('-', ' ').replace('_', ' ')\n",
    "    texto = ' '.join(texto.split())\n",
    "    return texto\n",
    "\n",
    "# =========================\n",
    "# Caminho\n",
    "# =========================\n",
    "caminho = r\"C:\\Users\\john-\\OneDrive - Universidade Federal da Para√≠ba\\√Årea de Trabalho\\Artigo - Estat√≠stica\\projeto-evasao\\data\\processed\"\n",
    "\n",
    "# =========================\n",
    "# Leitura dos arquivos\n",
    "# =========================\n",
    "ml_iq_2018_2023 = pd.read_csv(os.path.join(caminho, 'ml_iq_2018_2023.csv'))\n",
    "media_salarial_cursos_2018_2023 = pd.read_csv(os.path.join(caminho, 'media_salarial_cursos_2018_2023.csv'))\n",
    "\n",
    "# =========================\n",
    "# Tratamento da coluna C√ìDIGO_DO_MUNIC√çPIO\n",
    "# =========================\n",
    "cod_mun = (\n",
    "    ml_iq_2018_2023['C√ìDIGO_DO_MUNIC√çPIO']\n",
    "    .astype(str)\n",
    "    .str.replace('.', '', regex=False)\n",
    "    .str[:-1]\n",
    ")\n",
    "\n",
    "# Converte para n√∫mero, for√ßando valores inv√°lidos a NaN e usando Int64 para permitir nulos\n",
    "ml_iq_2018_2023['C√ìDIGO_DO_MUNIC√çPIO'] = pd.to_numeric(cod_mun, errors='coerce').astype('Int64')\n",
    "\n",
    "print(f\"Valores nulos ap√≥s tratamento: {ml_iq_2018_2023['C√ìDIGO_DO_MUNIC√çPIO'].isna().sum()}\")\n",
    "\n",
    "# =========================\n",
    "# Padroniza√ß√£o dos nomes dos cursos\n",
    "# =========================\n",
    "ml_iq_2018_2023['√ÅREA_DE_AVALIA√á√ÉO'] = ml_iq_2018_2023['√ÅREA_DE_AVALIA√á√ÉO'].apply(padronizar_texto)\n",
    "media_salarial_cursos_2018_2023['CURSOS'] = media_salarial_cursos_2018_2023['CURSOS'].apply(padronizar_texto)\n",
    "\n",
    "# =========================\n",
    "# Merge dos dataframes\n",
    "# =========================\n",
    "df_merged = ml_iq_2018_2023.merge(\n",
    "    media_salarial_cursos_2018_2023,\n",
    "    left_on=['C√ìDIGO_DO_MUNIC√çPIO', '√ÅREA_DE_AVALIA√á√ÉO'],\n",
    "    right_on=['mun', 'CURSOS'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Criar coluna 'salario'\n",
    "# =========================\n",
    "df_merged['salario'] = df_merged['media_salarial_media_2018_2023']\n",
    "\n",
    "# =========================\n",
    "# Salvar o novo dataframe\n",
    "# =========================\n",
    "df_merged.to_csv(\n",
    "    os.path.join(caminho, 'ml_iq_2018_2023.csv'),\n",
    "    index=False,\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Merge conclu√≠do com sucesso e coluna 'salario' adicionada!\")\n",
    "\n",
    "# =========================\n",
    "# Verificar combina√ß√µes sem sal√°rio\n",
    "# =========================\n",
    "na_salario = df_merged[df_merged['salario'].isna()]\n",
    "\n",
    "print(f\"\\nüîé Total de registros sem sal√°rio encontrado: {len(na_salario)}\")\n",
    "\n",
    "combinacoes_sem_match = na_salario[['C√ìDIGO_DO_MUNIC√çPIO', '√ÅREA_DE_AVALIA√á√ÉO']].drop_duplicates()\n",
    "\n",
    "print(\"\\nüö© Combina√ß√µes sem correspond√™ncia de sal√°rio:\\n\")\n",
    "print(combinacoes_sem_match)\n",
    "\n",
    "combinacoes_sem_match.to_csv(\n",
    "    os.path.join(caminho, 'combinacoes_sem_salario.csv'),\n",
    "    index=False,\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Arquivo 'combinacoes_sem_salario.csv' salvo com sucesso!\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9094cd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas atuais: ['C√ìDIGO_DA_IES', 'NOME_DA_IES', 'SIGLA_DA_IES', 'ORGANIZA√á√ÉO_ACAD√äMICA', 'CATEGORIA_ADMINISTRATIVA', 'C√ìDIGO_DO_CURSO', 'C√ìDIGO_DA_√ÅREA', '√ÅREA_DE_AVALIA√á√ÉO', 'MODALIDADE_DE_ENSINO', 'C√ìDIGO_DO_MUNIC√çPIO', 'MUNIC√çPIO_DO_CURSO', 'SIGLA_DA_UF', 'NOTA_PADRONIZADA_-_IDD', 'NOTA_PADRONIZADA_-_ORGANIZA√á√ÉO_DID√ÅTICO-PEDAG√ìGICA', 'NOTA_PADRONIZADA_-_INFRAESTRUTURA_E_INSTALA√á√ïES_F√çSICAS', 'NOTA_PADRONIZADA_-_OPORTUNIDADE_DE_AMPLIA√á√ÉO_DA_FORMA√á√ÉO', 'NOTA_PADRONIZADA_-_MESTRES', 'NOTA_PADRONIZADA_-_DOUTORES', 'MEDIA_CONCEITO_ENADE_(CONT√çNUO)', 'IDD_(CONT√çNUO)', 'CONCEITO_M√âDIO_DE_GRADUA√á√ÉO', 'IGC_(CONT√çNUO)', 'TDA', 'TDA_binaria', 'mun', 'CURSOS', 'media_salarial_media_2018_2023', 'salario']\n",
      "Arquivo salvo sem as colunas indicadas.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Caminho do arquivo\n",
    "caminho = r\"C:\\Users\\john-\\OneDrive - Universidade Federal da Para√≠ba\\√Årea de Trabalho\\Artigo - Estat√≠stica\\projeto-evasao\\data\\processed\"\n",
    "arquivo = \"ml_iq_2018_2023.csv\"\n",
    "\n",
    "# Carregar o dataframe\n",
    "df_merged = pd.read_csv(os.path.join(caminho, arquivo))\n",
    "\n",
    "# Mostrar as colunas atuais para garantir que as que deseja excluir existem\n",
    "print(\"Colunas atuais:\", df_merged.columns.tolist())\n",
    "\n",
    "# Excluir as colunas, ignorando erro se n√£o existir\n",
    "colunas_para_excluir = ['mun', 'CURSOS', 'media_salarial_media_2018_2023', 'salario']\n",
    "df_merged = df_merged.drop(columns=[col for col in colunas_para_excluir if col in df_merged.columns])\n",
    "\n",
    "# Salvar o novo dataframe sem essas colunas\n",
    "df_merged.to_csv(\n",
    "    os.path.join(caminho, 'ml_iq_2018_2023_sem_colunas.csv'),\n",
    "    index=False,\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "\n",
    "print(\"Arquivo salvo sem as colunas indicadas.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4deb9d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo salvo em: C:\\Users\\john-\\OneDrive - Universidade Federal da Para√≠ba\\√Årea de Trabalho\\Artigo - Estat√≠stica\\projeto-evasao\\data\\processed\\ml_iq_2018_2023_alterado.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Caminho do arquivo original\n",
    "caminho_arquivo = r\"C:\\Users\\john-\\OneDrive - Universidade Federal da Para√≠ba\\√Årea de Trabalho\\Artigo - Estat√≠stica\\projeto-evasao\\data\\processed\\ml_iq_2018_2023.csv\"\n",
    "\n",
    "# Carregar o DataFrame\n",
    "ml_iq_2018_2023 = pd.read_csv(caminho_arquivo)\n",
    "\n",
    "# Garantir que a coluna seja string\n",
    "ml_iq_2018_2023['C√ìDIGO_DO_MUNIC√çPIO'] = ml_iq_2018_2023['C√ìDIGO_DO_MUNIC√çPIO'].astype(str)\n",
    "\n",
    "# Pegar os 6 primeiros d√≠gitos\n",
    "ml_iq_2018_2023['C√ìDIGO_DO_MUNIC√çPIO'] = ml_iq_2018_2023['C√ìDIGO_DO_MUNIC√çPIO'].str[:6]\n",
    "\n",
    "# Converter para inteiro\n",
    "ml_iq_2018_2023['C√ìDIGO_DO_MUNIC√çPIO'] = ml_iq_2018_2023['C√ìDIGO_DO_MUNIC√çPIO'].astype(int)\n",
    "\n",
    "# Salvar em um novo arquivo CSV\n",
    "novo_caminho = r\"C:\\Users\\john-\\OneDrive - Universidade Federal da Para√≠ba\\√Årea de Trabalho\\Artigo - Estat√≠stica\\projeto-evasao\\data\\processed\\ml_iq_2018_2023_alterado.csv\"\n",
    "ml_iq_2018_2023.to_csv(novo_caminho, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"Arquivo salvo em:\", novo_caminho)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8da7384d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo salvo ap√≥s remo√ß√£o de missing values.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Caminho do arquivo\n",
    "caminho = r\"C:\\Users\\john-\\OneDrive - Universidade Federal da Para√≠ba\\√Årea de Trabalho\\Artigo - Estat√≠stica\\projeto-evasao\\data\\processed\"\n",
    "arquivo = \"ml_iq_2018_2023.csv\"\n",
    "caminho_arquivo = os.path.join(caminho, arquivo)\n",
    "\n",
    "# Carregar o dataframe\n",
    "df = pd.read_csv(caminho_arquivo)\n",
    "\n",
    "# Remover linhas com missing values\n",
    "df_limpo = df.dropna()\n",
    "\n",
    "# Salvar sobrescrevendo o arquivo original\n",
    "df_limpo.to_csv(caminho_arquivo, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"Arquivo salvo ap√≥s remo√ß√£o de missing values.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4efcfdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overflow: resultado √© praticamente zero.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Tentando diretamente (gera overflow)\n",
    "try:\n",
    "    resultado = 1 / (1 + math.exp(9995))\n",
    "    print(resultado)\n",
    "except OverflowError:\n",
    "    print(\"Overflow: resultado √© praticamente zero.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
